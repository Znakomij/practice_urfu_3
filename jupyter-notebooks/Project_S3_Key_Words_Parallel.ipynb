{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Получение ключевых слов для Проектного практикума - Учебная задача (семестр 3)\n",
    "\n",
    "Черновое решение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Установка зависимостей (если не установлены ранее)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Установка PyTorch для ускорителей CUDA\n",
    "# %pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Установка зависимостей для модели\n",
    "# %pip install transformers sentencepiece "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Установка зависимостей для параллельной обработки и блокнота\n",
    "# %pip install pandas ipywidgets jupyter IProgress protobuf joblib tdqm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импорты, константы и настройки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт библиотек\n",
    "from os.path import join as path_join\n",
    "from os.path import exists as path_exists\n",
    "from os import makedirs\n",
    "\n",
    "from gc import collect as gc_collect\n",
    "\n",
    "from torch.cuda import is_available as cuda_is_available\n",
    "from torch.cuda import device_count as cuda_device_count\n",
    "from torch.cuda import get_device_name as cuda_get_device_name\n",
    "from torch.cuda import empty_cache as cuda_empty_cache\n",
    "from torch import no_grad\n",
    "from torch import device\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "\n",
    "from itertools import groupby\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer, BatchEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Константы \n",
    "KW_MAX_LENGTH: int = 64\n",
    "KW_TOP_P: float = 1.0\n",
    "\n",
    "PART_FROM: int = 100_000    # Чать от индекса\n",
    "PART_TO: int = 100_100      # Чать до индекса\n",
    "PACK_SIZE: int = 500        # Сохранять по\n",
    "\n",
    "N_JOBS: int = 1        # Тут лучше не переусердствовать, \n",
    "BATCH_SIZE: int = 4    # так как VRAM может не хватить\n",
    "\n",
    "MODEL_NAME: str = '0x7194633/keyt5-large'\n",
    "\n",
    "PATH_TO_DS: str = '.././data/cleared/'      # '..' из-за того, что блокнот не руте\n",
    "DS_FILENAME: str = 'cleared_dataset.csv'\n",
    "\n",
    "PATH_TO_KW_PARTS: str = '.././data/cleared/key_words/'  # '..' из-за того, что блокнот не руте\n",
    "NAME_OF_KW_PARTS: str = 'key_words'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 - NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# Вывод устройств CUDA\n",
    "for c in range(cuda_device_count()):\n",
    "    name = cuda_get_device_name(c)\n",
    "    print(f'cuda:{c} - {name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Настройка ускорителя CUDA\n",
    "CUDA_DEVICE_INDEX: int = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Путь .././data/cleared/key_words/ создан/существует: True\n"
     ]
    }
   ],
   "source": [
    "# Создание структуры каталогов для данных\n",
    "def create_paths(fullpath: str) -> bool:\n",
    "    '''Создание каталогов с подкаталогами'''\n",
    "    makedirs(fullpath, exist_ok=True)\n",
    "    return path_exists(fullpath)\n",
    "\n",
    "print(f'Путь {PATH_TO_KW_PARTS} создан/существует: {create_paths(PATH_TO_KW_PARTS)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чтение датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 499800 entries, 0 to 499999\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   rating_int    499800 non-null  int64 \n",
      " 1   rubrics_list  499800 non-null  object\n",
      " 2   cleared_text  499800 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 15.3+ MB\n"
     ]
    }
   ],
   "source": [
    "#Чтение датасета\n",
    "df_data: pd.DataFrame = pd.read_csv(\n",
    "    path_join(PATH_TO_DS, DS_FILENAME),\n",
    "    sep=';',\n",
    "    index_col='indx')\n",
    "df_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Получение ключевых слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функции получения ключевых слов из модели\n",
    "def get_key_words_batch(\n",
    "        texts: pd.Series, \n",
    "        batch_size: int,\n",
    "        torch_device: device,\n",
    "        tokenizer: T5Tokenizer,\n",
    "        model: T5ForConditionalGeneration,\n",
    "        **kwargs\n",
    "        ) -> list[tuple[int, str]]:\n",
    "    '''Пакетный запрос ключевых слов в модели'''\n",
    "    # Получаем стартовый индекс (для сохранения индексов)\n",
    "    indx_list: list[int] = list(texts.index)\\\n",
    "    \n",
    "    # Деление на пакеты\n",
    "    result: list[tuple[int, str]] = []\n",
    "    for batch in range(0, len(texts), batch_size):\n",
    "        inputs: BatchEncoding = tokenizer(\n",
    "            texts[batch:batch+batch_size].to_list(), \n",
    "            return_tensors='pt',\n",
    "            padding='longest'\n",
    "            ).to(torch_device)\n",
    "        \n",
    "        with no_grad():\n",
    "            hypotheses = model.generate(**inputs, num_beams=5, **kwargs).to(torch_device)\n",
    "\n",
    "        decodeds: list[str] = tokenizer.batch_decode(hypotheses, skip_special_tokens=True)\n",
    "        \n",
    "        # Парсинг списка ключевых слов\n",
    "        for indx, decoded in zip(indx_list[batch:batch+batch_size], decodeds):\n",
    "            decoded_list: list[str] = decoded.replace('; ', ';') \\\n",
    "                .replace(' ;', ';').lower().split(';')[:-1]\n",
    "            decoded_list: list[str] = [el for el, _ in groupby(decoded_list)]\n",
    "            row: tuple[int, str] = (indx, decoded_list)\n",
    "            result.append(row)\n",
    "    return result\n",
    "\n",
    "def get_key_words(texts: pd.Series) -> pd.Series:\n",
    "    '''Получение ключевых слов для массива текстов'''\n",
    "    if not cuda_is_available():\n",
    "        raise RuntimeError('Ускоритель CUDA не доступен! Вычисление на CPU может занять годы')\n",
    "    torch_device: device = device(f'cuda:{CUDA_DEVICE_INDEX}')\n",
    "    print(f'Расчеты будут вестись на: {torch_device} ({cuda_get_device_name(torch_device)})')\n",
    "\n",
    "    # Создание инстанции модели\n",
    "    tokenizer: T5Tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME, legacy=False)\n",
    "    model: T5ForConditionalGeneration = T5ForConditionalGeneration \\\n",
    "        .from_pretrained(MODEL_NAME) \\\n",
    "        .to(torch_device)\n",
    "    \n",
    "    try:\n",
    "        result: list[tuple[int, str]] = get_key_words_batch(\n",
    "            texts,\n",
    "            BATCH_SIZE,\n",
    "            torch_device,\n",
    "            tokenizer, \n",
    "            model, \n",
    "            top_p=KW_TOP_P, \n",
    "            max_length=KW_MAX_LENGTH)\n",
    "    except Exception as ex:\n",
    "        raise Exception(ex)\n",
    "    finally:\n",
    "        # Чистка памяти (иначе видеопамять кончится)\n",
    "        cuda_empty_cache()\n",
    "        del model, tokenizer, torch_device\n",
    "        gc_collect()\n",
    "    \n",
    "    # Сборка серии\n",
    "    idx = [x[0] for x in result]\n",
    "    vals = [x[1] for x in result]\n",
    "    return pd.Series(vals, index=idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Датасет оптимально делить на части и вычислять на разных PC\n",
    "df_part = df_data[PART_FROM:PART_TO]\n",
    "parts: list[(int, int, pd.DataFrame)] = []\n",
    "\n",
    "for pack in range(0, len(df_part), PACK_SIZE):\n",
    "    df_pack = df_part[pack:pack+PACK_SIZE]\n",
    "    parts.append((PART_FROM+pack, PART_FROM+pack+len(df_pack), df_pack))\n",
    "\n",
    "def part_calc(f: int, t: int, df_data: pd.DataFrame) -> pd.Series:\n",
    "        '''Получение и сохранение ключевых слов'''\n",
    "        try:\n",
    "            print(f'-----> From {f} To {t}')\n",
    "            result_ser: pd.Series = get_key_words(df_data['cleared_text'])\n",
    "            result_ser.to_csv(\n",
    "                path_join(PATH_TO_KW_PARTS, f'{NAME_OF_KW_PARTS}_{f}_{t}.csv'),\n",
    "                encoding='utf-8-sig',\n",
    "                sep=';',\n",
    "                index_label='indx')\n",
    "            return result_ser\n",
    "        except Exception as ex:\n",
    "            print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Минимизация памяти для ускорения передачи\n",
    "# при параллельном вычислении\n",
    "del df_data, df_part, df_pack\n",
    "gc_collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----> From 100000 To 100100\n",
      "Расчеты будут вестись на: cuda:0 (NVIDIA GeForce RTX 3060 Laptop GPU)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:54<00:00, 54.58s/it]\n"
     ]
    }
   ],
   "source": [
    "# Запуск получения ключевых слов в потоках или в одном\n",
    "if N_JOBS < 2:\n",
    "    for f, t, df in tqdm(parts):\n",
    "        part_calc(f, t, df)\n",
    "else:\n",
    "    Parallel(\n",
    "        n_jobs=N_JOBS,\n",
    "        # backend=\"threading\",\n",
    "        # backend=\"multiprocessing\",\n",
    "        verbose=1)(delayed(part_calc) \\\n",
    "                (f, t, df) for f, t, df in tqdm(parts))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
